### Regularization正则化
在数学与计算机科学中，尤其是在机器学习领域中，**正则化**（英语：regularization）是指为解决[适定性问题](https://zh.wikipedia.org/wiki/%E9%80%82%E5%AE%9A%E6%80%A7%E9%97%AE%E9%A2%98 "适定性问题")或[过拟合](https://zh.wikipedia.org/wiki/%E8%BF%87%E6%8B%9F%E5%90%88 "过拟合")而加入额外信息的过程。
1.$L_p$正则化
所谓[范数](https://zh.wikipedia.org/wiki/%E8%8C%83%E6%95%B0 "范数")即是抽象之长度，通常意义上满足长度的三种性质：非负性、齐次性和三角不等式。
以函数的观点来看，范数是定义在${\mathbb {R} ^{n}\to \mathbb {R} }$的函数；并且它和损失函数类似，也具有下确界。后一性质是由范数的非负性和齐次性保证的。  
这一特性使得$L_p$-范数天然适合做正则项，因为目标函数仍可用[梯度下降](https://zh.wikipedia.org/wiki/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D "梯度下降")等方式求解最优化问题。  
$L_p$-范数作为正则项时被称为$L_p$-正则项。
2.提前停止
[提前停止](https://zh.wikipedia.org/wiki/%E6%8F%90%E5%89%8D%E5%81%9C%E6%AD%A2 "提前停止")可看做是**时间维度上的正则化**。**直觉上，随着迭代次数的增加，如梯度下降这样的训练算法倾向于学习愈加复杂的模型。在时间维度上进行正则化有助于控制模型复杂度，提升泛化能力**。在实践中，提前停止一般是在训练集上进行训练，而后在统计上独立的验证集上进行评估；当模型在验证集上的性能不再提升时，就提前停止训练。最后，可在测试集上对模型性能做最后测试。
